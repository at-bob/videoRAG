===================================================
                VideoRAG - Multimodal Video Retrieval System
===================================================

This project implements a Retrieval-Augmented Generation (RAG) pipeline for video content. 
It enables natural language queries to retrieve relevant video moments using 
transcripts, visual keyframes, and OCR-extracted slide text embeddings.

ğŸ“Œ GitHub Repository: https://github.com/at-bob/videoRAG


==========================================
ğŸ“ Project Structure
==========================================

VideoRAG/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ transcripts/       # Stores transcript JSON files
â”‚   â”œâ”€â”€ frames/            # Extracted video frames as images
â”‚   â”œâ”€â”€ embeddings/        # Generated embeddings for text, image, and OCR
â”‚   â””â”€â”€ video.mp4          # Input video file for processing
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing/   # Scripts for data preprocessing
â”‚   â””â”€â”€ retrieval/         # Retrieval models and logic
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ gold_test_set.json # Test set with answerable and unanswerable queries
â”‚   â””â”€â”€ evaluate_retrieval.py # Evaluation script for model benchmarking
â””â”€â”€ streamlit.py           # Interactive UI using Streamlit


==========================================
ğŸš€ Setup & Installation
==========================================

1. Clone the repository:
   git clone https://github.com/at-bob/videoRAG.git
   cd videoRAG

2. Create and activate a virtual environment:
   python3 -m venv .venv
   source .venv/bin/activate

3. Install required dependencies:
   pip install --upgrade pip
   pip install -r requirements.txt
   pip install git+https://github.com/openai/CLIP.git

4. (Optional for macOS M1/M2 users)
   brew install openssl
   export LDFLAGS="-L/opt/homebrew/opt/openssl/lib"
   export CPPFLAGS="-I/opt/homebrew/opt/openssl/include"


==========================================
ğŸ“š Data Processing Pipeline
==========================================

1. **Extract Frames:**
   Run: `python src/data_processing/extract_frames.py`
   - Extracts video frames every 2 seconds and saves them in `data/frames/`.

2. **Transcribe Audio (Whisper):**
   Run: `python src/data_processing/transcribe.py`
   - Uses OpenAI Whisper to generate transcripts stored in JSON.

3. **Generate Text Embeddings:**
   Run: `python src/data_processing/generate_text_embeddings.py`
   - Generates embeddings from transcripts using MiniLM.

4. **Generate Image Embeddings:**
   Run: `python src/data_processing/generate_image_embeddings.py`
   - Extracts embeddings from keyframes using CLIP.

5. **Generate OCR + Embeddings:**
   Run: `python src/data_processing/ocr_frame_texts.py`
   - Extracts slide text from frames using Tesseract OCR and generates embeddings.

==========================================
ğŸ” Retrieval Methods
==========================================

- FAISS (Dense Vector Similarity Search)
- PgVector (PostgreSQL Vector Search)
- TF-IDF (Lexical Matching)
- BM25 (Lexical Matching)
- Multimodal (Transcript + Visual Embeddings)
- Multimodal+OCR (Transcript + Visual + Slide Text Embeddings)

To run the evaluation:
```bash
python evaluation/evaluate_retrieval.py
```
==========================================
ğŸ® Streamlit Interactive UI
Launch the interactive interface:

```bash
streamlit run streamlit.py
```
Enter a natural language query.

Select one of the retrieval models.

View the retrieved timestamp and system confidence.

==========================================
ğŸ“ˆ Evaluation Metrics
Top-1 Accuracy: Correct retrievals within a Â±10 second tolerance.

Rejection Quality: Ability to reject unanswerable queries.

Latency: Average retrieval time per query.

Evaluation Results can be reviewed in the terminal after running the evaluation script.

==========================================